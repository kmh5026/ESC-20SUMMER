{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "input=np.array([[2,0,2,1,3,2],\n",
    "            [0,2,0,2,2,2],\n",
    "            [1,0,1,3,1,1],\n",
    "            [0,0,1,1,1,0],\n",
    "            [0,1,3,4,1,0],\n",
    "            [0,1,0,0,5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 2., 0., 2., 1., 3., 2., 0.],\n",
       "       [0., 0., 2., 0., 2., 2., 2., 0.],\n",
       "       [0., 1., 0., 1., 3., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 1., 3., 4., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 5., 2., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero padding\n",
    "input_=np.zeros((8,8))\n",
    "input_[1:7,1:7]=input\n",
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter\n",
    "filter=np.array([[1,0,0],\n",
    "            [0,1,0],\n",
    "            [0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  0.,  4.,  3.,  5.,  2.],\n",
       "       [ 0.,  5.,  3.,  5.,  4.,  5.],\n",
       "       [ 1.,  1.,  4.,  4.,  3.,  3.],\n",
       "       [ 1.,  4.,  5.,  3.,  4.,  1.],\n",
       "       [ 1.,  1.,  3., 10.,  4.,  1.],\n",
       "       [ 0.,  1.,  1.,  3.,  9.,  3.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution\n",
    "row= input.shape[0]-filter.shape[0]+2*1+1\n",
    "col= input.shape[1]-filter.shape[1]+2*1+1\n",
    "\n",
    "result2=[]\n",
    "\n",
    "for rn in range(row):\n",
    "    for cn in range(col):\n",
    "        result1=input_[rn:rn+filter.shape[0],cn:cn+filter.shape[1]]*filter\n",
    "        result2.append(np.sum(result1))\n",
    "output=np.array(result2).reshape(row,col)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.],\n",
       "       [ 4.,  5.,  4.],\n",
       "       [ 1., 10.,  9.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max pooling\n",
    "\n",
    "def max_pooling(x, stride):\n",
    "    mp =[]\n",
    "    for i in range(0,len(x)-1,stride):\n",
    "        for j in range(0,len(x)-1,stride):\n",
    "            mp.append(np.max(x[i:i+stride, j:j+stride]))\n",
    "    \n",
    "    mp = np.array(mp)\n",
    "    return mp.reshape(stride+1, stride+1)\n",
    "\n",
    "output_=max_pooling(output,2)\n",
    "output_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2번"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 기존 CNN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device=='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started. It takes sometime.\n",
      "Epoch: 0001 cost= 0.192842379\n",
      "Epoch: 0002 cost= 0.050659336\n",
      "Epoch: 0003 cost= 0.036905844\n",
      "Epoch: 0004 cost= 0.028666601\n",
      "Epoch: 0005 cost= 0.022915171\n",
      "Epoch: 0006 cost= 0.019199846\n",
      "Epoch: 0007 cost= 0.015928745\n",
      "Epoch: 0008 cost= 0.015398595\n",
      "Epoch: 0009 cost= 0.012690732\n",
      "Epoch: 0010 cost= 0.010419538\n",
      "Epoch: 0011 cost= 0.010241176\n",
      "Epoch: 0012 cost= 0.008266630\n",
      "Epoch: 0013 cost= 0.009403898\n",
      "Epoch: 0014 cost= 0.006834675\n",
      "Epoch: 0015 cost= 0.007971950\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "learning_rate=0.001\n",
    "training_epochs=15\n",
    "batch_size=100\n",
    "\n",
    "#MNIST dataset\n",
    "mnist_train=dsets.MNIST(root='MNIST_data/',\n",
    "                       train=True,\n",
    "                       transform=transforms.ToTensor(),\n",
    "                       download=True)\n",
    "mnist_test=dsets.MNIST(root='MNIST_data/',\n",
    "                      train=False,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download=True)\n",
    "\n",
    "# dataset loader\n",
    "data_loader=DataLoader(dataset=mnist_train,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      drop_last=True)\n",
    "\n",
    "# class로 CNN모델 설계\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        \n",
    "        # layer1\n",
    "        # ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        \n",
    "        # layer2\n",
    "        # ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        \n",
    "        # layer3\n",
    "        # ImgIn shape=(?, 7, 7, 64)\n",
    "        #    Conv      ->(?, 7, 7, 128)\n",
    "        #    Pool      ->(?, 4, 4, 128)\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2,padding=1))\n",
    "        \n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1=nn.Linear(4*4*128,625,bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4=nn.Sequential(\n",
    "            self.fc1,\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=1-self.keep_prob))\n",
    "        \n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        out=self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "        out=out.view(out.size(0),-1) # Flatten them for FC\n",
    "        out=self.layer4(out)\n",
    "        out=self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "# 모델 선언\n",
    "model=CNN().to(device)\n",
    "\n",
    "# cost, optimizer\n",
    "criterion=nn.CrossEntropyLoss().to(device) #softmax is internally computed\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# Train\n",
    "total_batch=len(data_loader)\n",
    "\n",
    "print('Learning Started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "        \n",
    "        hypothesis=model(X)\n",
    "        cost=criterion(hypothesis,Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost+= cost/total_batch\n",
    "        \n",
    "    print('Epoch:','%04d'%(epoch+1), 'cost=','{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9677000045776367\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "with torch.no_grad():\n",
    "    \n",
    "    X_test=mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test=mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction=model(X_test)\n",
    "    correct_prediction=torch.argmax(prediction,1)==Y_test \n",
    "    # torch.argmax(a,axis): a의 axis에 해당하는 값들 중 가장 큰 값의 index 반환\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 수정한 CNN 모델\n",
    "- layer1의 kernel_size=4, layer3의 stride=2\n",
    "- layer3의 output size=(2,2,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started. It takes sometime.\n",
      "Epoch: 0001 cost= 0.270708263\n",
      "Epoch: 0002 cost= 0.068952031\n",
      "Epoch: 0003 cost= 0.046793386\n",
      "Epoch: 0004 cost= 0.037261110\n",
      "Epoch: 0005 cost= 0.030546447\n",
      "Epoch: 0006 cost= 0.023847545\n",
      "Epoch: 0007 cost= 0.022468038\n",
      "Epoch: 0008 cost= 0.018700982\n",
      "Epoch: 0009 cost= 0.016164649\n",
      "Epoch: 0010 cost= 0.013824138\n",
      "Epoch: 0011 cost= 0.015041474\n",
      "Epoch: 0012 cost= 0.010649967\n",
      "Epoch: 0013 cost= 0.011590094\n",
      "Epoch: 0014 cost= 0.008392265\n",
      "Epoch: 0015 cost= 0.011113419\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "learning_rate=0.001\n",
    "training_epochs=15\n",
    "batch_size=100\n",
    "\n",
    "#MNIST dataset\n",
    "mnist_train=dsets.MNIST(root='MNIST_data/',\n",
    "                       train=True,\n",
    "                       transform=transforms.ToTensor(),\n",
    "                       download=True)\n",
    "mnist_test=dsets.MNIST(root='MNIST_data/',\n",
    "                      train=False,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download=True)\n",
    "\n",
    "# dataset loader\n",
    "data_loader=DataLoader(dataset=mnist_train,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      drop_last=True)\n",
    "\n",
    "# class로 CNN모델 설계\n",
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2,self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        \n",
    "        # layer1\n",
    "        # ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 27, 27, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=4,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        \n",
    "        # layer2\n",
    "        # ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        \n",
    "        # layer3\n",
    "        # ImgIn shape=(?, 7, 7, 64)\n",
    "        #    Conv      ->(?, 4, 4, 128)\n",
    "        #    Pool      ->(?, 2, 2, 128)\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2,padding=1))\n",
    "        \n",
    "        # L4 FC 2x2x128 inputs -> 625 outputs\n",
    "        self.fc1=nn.Linear(2*2*128,625,bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4=nn.Sequential(\n",
    "            self.fc1,\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=1-self.keep_prob))\n",
    "        \n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        out=self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "        out=out.view(out.size(0),-1) # Flatten them for FC\n",
    "        out=self.layer4(out)\n",
    "        out=self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "# 모델 선언\n",
    "model=CNN2().to(device)\n",
    "\n",
    "# cost, optimizer\n",
    "criterion=nn.CrossEntropyLoss().to(device) #softmax is internally computed\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# Train\n",
    "total_batch=len(data_loader)\n",
    "\n",
    "print('Learning Started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "        \n",
    "        hypothesis=model(X)\n",
    "        cost=criterion(hypothesis,Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost+= cost/total_batch\n",
    "        \n",
    "    print('Epoch:','%04d'%(epoch+1), 'cost=','{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9883000254631042\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cost는 기존 모델보다 증가하였으나, 정확도 0.96 -> 0.98 로 오히려 상승\n",
    "- 기존 모델이 과적합이 된듯 하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
