{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pylab as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정 (learning rate, training epochs, batch_size)\n",
    "learning_rate = 0.1\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "drop_prob=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 100, bias=True)\n",
    "linear2 = torch.nn.Linear(100, 100, bias=True)\n",
    "linear3 = torch.nn.Linear(100, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "bn1 = torch.nn.BatchNorm1d(100)\n",
    "bn2 = torch.nn.BatchNorm1d(100)\n",
    "\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.5363e-01,  3.7224e-02, -1.5443e-01, -2.1791e-01,  1.7185e-01,\n",
       "         -2.0676e-01, -1.1819e-01, -1.6484e-01,  1.3565e-01,  2.4250e-02,\n",
       "          1.6574e-01,  1.4360e-01,  1.2099e-01,  1.0337e-01,  1.7177e-01,\n",
       "         -1.9295e-01, -1.3142e-01, -1.0130e-01, -1.7494e-01, -1.6558e-01,\n",
       "         -2.0379e-01, -7.8588e-02,  9.9025e-02, -8.9940e-02,  1.9087e-01,\n",
       "         -1.1381e-01, -2.3247e-01,  2.5474e-02, -5.6100e-03, -1.9829e-01,\n",
       "          1.4070e-01, -1.3431e-01, -2.0873e-01, -5.9762e-02,  5.9842e-02,\n",
       "         -1.5402e-01, -6.3408e-02, -1.8561e-01, -6.3792e-02, -9.9554e-02,\n",
       "         -4.6280e-02, -2.2085e-02, -6.4181e-02, -8.8129e-02, -1.1779e-01,\n",
       "         -9.2208e-02,  1.9029e-01, -5.3670e-02,  6.7792e-02,  1.1459e-01,\n",
       "         -2.1908e-01, -1.7011e-01,  1.5883e-01, -7.4235e-02,  5.7834e-02,\n",
       "          1.5231e-01,  7.3779e-03,  1.6984e-01,  1.6407e-01, -2.1601e-01,\n",
       "          7.8833e-02, -7.1080e-02,  1.5240e-01, -5.5697e-02, -1.5577e-01,\n",
       "         -1.1549e-01, -4.7567e-02, -2.0434e-01, -2.1423e-01, -2.1452e-01,\n",
       "          1.6130e-01, -1.2147e-02, -9.3916e-02,  3.6879e-02, -1.6198e-01,\n",
       "         -1.1210e-01, -2.3290e-01, -1.3912e-01, -1.3979e-01, -1.6228e-01,\n",
       "         -7.2859e-02,  2.6247e-02,  2.3078e-01,  8.0908e-02,  6.5113e-02,\n",
       "         -1.4710e-01, -8.8251e-02,  5.3629e-05, -2.9549e-02, -1.4262e-02,\n",
       "          2.1492e-01,  1.9601e-02,  1.9420e-01,  1.2333e-01, -3.5704e-02,\n",
       "          6.6095e-02,  1.7786e-01, -2.0372e-01, -6.5500e-02, -1.9327e-01],\n",
       "        [-1.6261e-01,  2.7402e-02, -2.0215e-01, -1.3036e-01, -1.6015e-01,\n",
       "         -1.9682e-01,  2.0154e-01, -8.3036e-02, -4.9693e-02, -3.4923e-02,\n",
       "          1.8051e-02, -4.1830e-02, -6.8295e-02,  2.0108e-01, -1.3497e-01,\n",
       "          1.8129e-01, -8.6083e-02,  1.6965e-01, -1.2008e-01,  1.8400e-02,\n",
       "          4.6700e-02, -1.1418e-01,  4.5555e-02,  4.6307e-02, -2.1611e-02,\n",
       "         -1.8609e-01, -6.4801e-02,  1.1509e-01,  9.5750e-02, -5.3854e-02,\n",
       "         -1.3600e-01, -1.0135e-01, -3.4693e-02, -1.8909e-01,  3.4169e-03,\n",
       "         -1.3837e-01,  1.3742e-02,  1.8433e-01, -1.1474e-01, -1.6652e-01,\n",
       "         -1.2712e-01,  8.1976e-02, -1.6082e-01, -1.9150e-01, -3.3551e-03,\n",
       "         -1.5622e-01, -1.3353e-01, -1.8725e-01,  1.9116e-01,  4.4212e-02,\n",
       "          8.9127e-02,  1.9899e-01, -7.1111e-03, -1.9527e-01, -2.2772e-01,\n",
       "          1.5613e-01, -7.1003e-02,  1.2706e-01,  9.2407e-02,  5.2200e-02,\n",
       "         -1.5704e-01,  1.8312e-01,  6.6336e-02,  1.6012e-01,  9.8995e-02,\n",
       "         -5.6382e-02, -8.1096e-02,  1.6669e-01,  1.2146e-01,  1.1560e-01,\n",
       "         -1.2108e-01,  1.8470e-01, -9.9602e-02, -1.6289e-01, -1.6082e-01,\n",
       "          4.3035e-02, -7.6779e-02,  1.3109e-01,  2.0179e-01, -2.0127e-01,\n",
       "          1.8082e-02,  2.2391e-01, -1.7218e-01,  1.1411e-01,  2.1086e-01,\n",
       "         -1.8156e-01, -5.9770e-02, -1.5770e-02, -1.0864e-01, -7.3720e-02,\n",
       "          3.2953e-03, -1.9188e-01,  2.5363e-02, -3.4499e-02,  9.5383e-02,\n",
       "          1.9197e-01, -2.1002e-01, -2.1855e-01, -7.5892e-02,  8.8298e-02],\n",
       "        [-4.3819e-02, -1.3198e-01, -1.5733e-01,  6.6590e-02,  6.6329e-03,\n",
       "          7.0302e-02,  2.2660e-01, -6.0459e-02,  1.7758e-01,  1.5719e-01,\n",
       "          3.3877e-02,  5.6040e-02, -1.0448e-01,  1.3677e-01,  1.0245e-01,\n",
       "         -4.6746e-02,  1.4473e-01,  1.8288e-01,  1.3100e-01,  8.1228e-02,\n",
       "          1.4288e-01,  1.2463e-01, -1.6200e-01,  1.7967e-01, -9.0997e-02,\n",
       "         -8.2011e-02,  1.0605e-01,  1.6285e-01, -2.2880e-01, -1.5484e-01,\n",
       "         -1.0124e-01, -1.0212e-02,  9.2198e-02,  1.2281e-02,  1.4343e-01,\n",
       "          8.3754e-02, -1.9806e-01,  1.8833e-01, -6.7852e-02, -5.6224e-03,\n",
       "         -1.7611e-01,  4.5785e-02, -8.4637e-02,  9.0063e-02, -2.1847e-01,\n",
       "          8.6072e-02, -2.3295e-01, -1.2239e-01, -1.0612e-01, -4.2571e-02,\n",
       "         -1.8301e-01, -2.1904e-01,  2.4971e-02, -2.0969e-01,  4.0934e-02,\n",
       "         -1.2236e-01,  1.1571e-01, -2.1929e-01, -1.5147e-01, -4.2563e-02,\n",
       "         -7.2175e-02,  9.7566e-02, -1.7015e-01, -6.2575e-02, -2.7111e-02,\n",
       "         -2.2278e-01, -9.2933e-02,  2.8271e-02, -5.8891e-02,  2.2244e-02,\n",
       "         -1.1623e-01, -2.1662e-01,  2.0583e-01, -1.7303e-01, -3.6864e-02,\n",
       "          2.3208e-01, -2.3139e-01, -2.0522e-02,  1.4906e-01,  1.5153e-01,\n",
       "          9.1475e-02, -1.8194e-02, -1.3011e-01, -1.8199e-01, -2.2996e-01,\n",
       "          7.1974e-02, -8.3742e-02, -1.8663e-01,  9.1356e-02, -8.7991e-02,\n",
       "          1.3639e-01, -2.1662e-01, -5.2053e-03,  1.2447e-01, -1.5871e-01,\n",
       "          1.4103e-01,  6.0991e-02,  9.6776e-03,  1.9738e-02,  1.6704e-01],\n",
       "        [-6.8208e-02, -8.3626e-02, -1.0211e-01, -9.8221e-02,  7.9912e-02,\n",
       "         -1.0720e-01, -1.8234e-01,  5.7346e-02,  7.0799e-02,  2.6133e-02,\n",
       "          1.8286e-01, -1.6046e-01,  1.8644e-01,  2.3004e-01,  2.0393e-01,\n",
       "          1.6885e-01,  6.3566e-02, -1.2711e-01, -1.8766e-01, -1.8086e-01,\n",
       "         -8.3370e-02,  1.6631e-01, -1.0022e-01, -3.3123e-02, -5.0705e-02,\n",
       "         -1.7223e-02,  2.3109e-01,  1.3763e-01, -1.2049e-01, -2.0034e-01,\n",
       "         -1.2845e-01, -1.3054e-01, -2.7444e-02, -1.0258e-01,  1.4704e-02,\n",
       "          2.1900e-01,  7.2388e-03,  6.6019e-02,  1.1494e-01,  8.5098e-02,\n",
       "         -1.7542e-01,  8.7756e-02,  2.0181e-01,  1.8433e-01, -2.2514e-01,\n",
       "         -1.7474e-01, -9.4852e-02,  7.9412e-02, -1.7729e-01, -2.7461e-02,\n",
       "          3.6953e-02, -2.2923e-01,  1.5152e-01, -4.5772e-02, -1.1070e-01,\n",
       "         -2.1861e-01,  1.4866e-01,  2.2497e-01, -2.3082e-01, -9.4893e-02,\n",
       "          5.6368e-02,  9.9969e-02, -1.9054e-01,  1.7170e-02,  1.3503e-01,\n",
       "         -1.8039e-01, -1.1080e-01, -1.7374e-01, -1.2138e-01,  8.6574e-02,\n",
       "         -3.3600e-03, -1.8472e-01,  1.7780e-02, -6.0903e-02,  1.1109e-01,\n",
       "          1.0007e-02,  1.4120e-02,  1.0735e-01,  1.2830e-01,  1.2249e-01,\n",
       "          8.2672e-02, -1.1453e-02,  2.1843e-01, -4.2019e-02,  3.8193e-02,\n",
       "          1.6267e-01,  2.2040e-01, -6.3176e-02, -7.7746e-03,  2.0945e-01,\n",
       "          1.0075e-01, -1.0152e-01,  7.8387e-02,  1.6229e-01,  1.4853e-01,\n",
       "         -8.7429e-02, -7.3214e-02,  5.2773e-02,  3.3000e-02,  8.4761e-02],\n",
       "        [ 6.3695e-02, -9.0031e-02,  1.4882e-01,  1.4810e-01, -8.1709e-02,\n",
       "          4.1348e-02,  9.4947e-02, -1.6060e-01,  5.2050e-02,  9.9703e-02,\n",
       "          9.6388e-02,  1.3022e-02, -1.1037e-01,  1.0941e-01, -6.6952e-02,\n",
       "         -1.7452e-01, -1.0040e-02, -2.1622e-01, -4.1491e-02,  1.8623e-01,\n",
       "         -2.1874e-01, -1.0139e-01,  1.7519e-01, -6.8671e-02,  2.0165e-01,\n",
       "          1.2292e-01,  9.1708e-02,  9.0287e-02,  4.7741e-02,  1.1900e-01,\n",
       "         -1.1485e-01, -1.8207e-01,  1.7657e-01, -9.1125e-04,  2.3325e-01,\n",
       "         -1.9628e-02, -7.2897e-02, -2.1179e-01, -5.1781e-02, -7.9019e-02,\n",
       "         -7.6630e-02,  1.8442e-01, -7.9531e-02, -3.1598e-02, -1.4313e-01,\n",
       "          3.0999e-02, -1.5964e-01, -2.3765e-02, -1.0593e-01,  4.5675e-02,\n",
       "          5.4463e-02, -2.2473e-01,  1.5208e-01, -3.9839e-02, -1.0590e-01,\n",
       "         -1.1634e-01,  5.7231e-02,  1.5241e-01,  1.2269e-01, -8.1615e-03,\n",
       "          2.2028e-01, -4.2219e-02,  8.1859e-02, -1.0044e-01, -1.4232e-01,\n",
       "          1.1021e-01,  2.0002e-01,  1.9337e-01, -8.5724e-02, -2.1776e-01,\n",
       "         -1.4007e-01, -1.1784e-01,  1.2000e-01, -2.3246e-01,  3.1121e-02,\n",
       "         -1.5758e-01,  5.9682e-02, -1.9521e-01, -2.7020e-02, -2.0006e-01,\n",
       "         -1.0141e-01,  6.4540e-02, -7.0123e-02, -1.3977e-01,  7.8127e-03,\n",
       "          1.0848e-01, -1.0527e-01,  1.5844e-01, -1.6911e-01,  1.5201e-01,\n",
       "         -1.4062e-02,  9.8984e-02, -6.7754e-02, -4.7663e-03,  1.6449e-01,\n",
       "         -1.7968e-01, -1.7160e-01,  1.1249e-01, -1.4384e-01,  4.2596e-02],\n",
       "        [ 1.0388e-01, -1.4174e-01, -1.2726e-01, -9.1542e-02,  8.7274e-02,\n",
       "         -1.2107e-01,  6.9721e-02, -4.4737e-02, -8.3058e-02, -1.5281e-01,\n",
       "          2.0583e-01,  1.1303e-01,  1.0957e-01,  5.9680e-02, -2.1702e-01,\n",
       "         -2.2017e-01,  7.4210e-02,  2.9386e-02, -1.0032e-01,  1.6729e-01,\n",
       "         -1.7264e-01, -9.7645e-02,  3.9745e-02,  8.7411e-02,  6.9515e-03,\n",
       "          1.9474e-01,  7.3076e-02, -1.6936e-02, -1.3199e-01,  1.7440e-02,\n",
       "         -6.4619e-02,  2.2775e-01, -7.4542e-02, -9.5485e-02,  2.3014e-01,\n",
       "         -2.8509e-02,  1.6285e-01, -1.6131e-01, -1.4991e-01, -1.9683e-01,\n",
       "         -1.0065e-01,  6.8881e-03, -2.1629e-01, -2.0902e-01,  1.6370e-01,\n",
       "         -1.3476e-01,  1.5408e-01,  2.9936e-02,  1.6993e-02, -1.9792e-01,\n",
       "          2.2396e-01,  2.3027e-01, -1.0956e-01, -1.9090e-01, -1.6224e-01,\n",
       "         -1.8046e-01, -8.2256e-02, -1.7299e-01,  2.0885e-01,  1.1791e-01,\n",
       "         -1.7396e-01, -4.1076e-02,  1.7690e-01, -1.0898e-01, -2.3728e-02,\n",
       "          1.7613e-01, -8.0775e-03, -4.0449e-02, -2.3332e-01,  6.5633e-02,\n",
       "         -3.8969e-02, -2.0736e-01,  1.2906e-01,  1.5134e-01,  1.5381e-01,\n",
       "          2.0885e-01, -2.2532e-01, -1.3151e-01,  2.1081e-01, -2.6267e-02,\n",
       "         -2.2747e-01,  1.6893e-02, -1.7286e-01, -1.7712e-01, -3.0087e-02,\n",
       "         -2.2076e-01, -1.7346e-01, -1.2391e-01, -1.7156e-01, -1.4755e-01,\n",
       "         -5.5902e-02,  2.1952e-01, -3.6748e-02, -1.9553e-01, -8.9831e-02,\n",
       "         -1.4618e-01, -2.3141e-01, -7.8738e-02,  1.6839e-01,  1.5081e-01],\n",
       "        [-1.7991e-01,  6.3122e-02,  7.2736e-02,  2.3086e-01,  7.4936e-02,\n",
       "         -1.5248e-01, -5.7542e-02,  1.8206e-01,  1.1410e-01,  1.0397e-01,\n",
       "         -1.7655e-01,  1.1765e-01, -7.3159e-02, -5.0936e-02,  2.0426e-01,\n",
       "         -1.6674e-01,  1.0161e-01,  4.4739e-02, -5.7718e-02, -6.6802e-03,\n",
       "         -1.2382e-01, -2.1101e-01,  9.0062e-03,  1.0121e-01,  9.7999e-02,\n",
       "          2.0308e-01,  1.3740e-01, -1.2971e-01, -1.2460e-01, -7.5695e-02,\n",
       "         -6.8722e-02,  2.2038e-01,  2.2852e-03,  1.6777e-01, -2.0812e-02,\n",
       "         -1.5988e-01,  2.0723e-01,  8.1032e-02, -1.5957e-01,  1.4333e-01,\n",
       "         -1.7146e-01, -2.1454e-01, -9.4124e-02, -1.5923e-01, -1.2623e-01,\n",
       "          8.6108e-02, -1.1754e-01, -6.1712e-02, -1.6750e-01, -5.1583e-02,\n",
       "          9.1026e-03, -2.0301e-02, -2.2124e-02, -1.2611e-01, -1.7245e-01,\n",
       "          1.7572e-01, -1.4879e-01, -9.7185e-02,  1.1032e-01, -1.8605e-02,\n",
       "          1.4351e-01, -2.1107e-01,  3.0257e-02,  2.2943e-01,  1.4947e-01,\n",
       "         -7.0465e-02,  2.5427e-02,  1.2922e-01,  2.0373e-01,  4.7857e-02,\n",
       "         -4.6123e-02,  2.1372e-01,  1.5075e-01,  1.2876e-01,  4.3734e-02,\n",
       "          1.4938e-01,  9.2614e-02,  1.6477e-01,  5.8951e-02,  2.1830e-01,\n",
       "          1.4947e-01, -8.9610e-02, -2.7363e-02, -3.4537e-02, -1.0041e-01,\n",
       "          2.2840e-01,  1.1642e-01, -2.1567e-01,  3.3433e-02,  2.3201e-01,\n",
       "         -1.1735e-01,  1.3169e-01, -3.1724e-02,  5.9646e-02, -7.4881e-02,\n",
       "          2.1255e-01, -8.6584e-02, -2.1520e-02,  1.3481e-01,  2.2251e-01],\n",
       "        [ 2.2311e-01,  2.4370e-02,  2.2458e-01, -1.6769e-01,  4.1256e-02,\n",
       "         -2.2737e-01, -2.4512e-02, -1.2722e-01,  1.4308e-01,  6.1935e-02,\n",
       "          1.0622e-01, -2.1993e-01,  2.6527e-04, -7.1281e-02, -1.3951e-01,\n",
       "         -8.7516e-03,  1.6361e-01,  7.6248e-02,  6.4330e-03,  1.0905e-01,\n",
       "         -8.9976e-02, -1.6726e-01,  1.1015e-01, -8.4702e-02,  1.4881e-01,\n",
       "          2.0205e-01,  7.7354e-02, -7.7583e-02, -1.9498e-01,  1.4543e-01,\n",
       "         -1.4704e-02, -4.6141e-02, -1.7838e-01, -7.8847e-03,  7.5260e-02,\n",
       "          6.7333e-02, -1.6888e-01,  1.3347e-01,  6.0266e-02, -1.5484e-01,\n",
       "         -7.8986e-02,  2.1458e-01,  8.4763e-02, -1.6429e-03,  6.3889e-03,\n",
       "          2.2892e-01,  8.4596e-02, -2.2020e-02,  4.5193e-03,  1.4785e-01,\n",
       "         -1.5501e-01,  6.9908e-02,  1.3040e-01,  1.6385e-01, -1.6658e-01,\n",
       "         -9.8265e-02, -1.3974e-01, -1.0477e-03, -9.7586e-02, -1.4478e-01,\n",
       "         -4.1410e-02, -4.6023e-02, -1.0382e-01,  8.3979e-02, -6.7641e-02,\n",
       "         -3.0434e-02, -1.2399e-02, -2.2633e-01,  3.5031e-02, -8.4910e-02,\n",
       "         -1.1830e-01, -7.3359e-02, -1.4608e-01,  6.2789e-03, -1.5052e-01,\n",
       "          1.8523e-01,  1.8561e-01,  5.2302e-02,  9.4343e-02,  3.0546e-02,\n",
       "         -2.2911e-01,  1.7179e-02, -1.6137e-01,  7.0628e-02,  4.2563e-02,\n",
       "         -1.4962e-01,  2.2875e-01,  1.1275e-01,  1.5518e-01,  1.0635e-02,\n",
       "          1.0966e-01,  2.0195e-01,  1.6587e-01, -9.2532e-02, -1.8335e-01,\n",
       "         -1.7753e-01, -1.7627e-01,  7.1908e-03, -1.2907e-01,  2.1050e-01],\n",
       "        [ 6.9962e-02, -1.5839e-01,  6.8588e-02, -2.1059e-01,  8.3680e-03,\n",
       "         -7.0644e-02,  5.2713e-03,  8.0996e-02,  2.6831e-02, -1.8298e-01,\n",
       "          6.3121e-02, -5.6603e-02, -4.1179e-02, -8.0834e-02,  4.2914e-02,\n",
       "         -5.7946e-02, -4.9517e-02,  2.2659e-01, -1.6797e-01, -5.6187e-02,\n",
       "         -1.2059e-01,  2.3124e-01, -2.2712e-01, -1.1280e-01,  2.5356e-02,\n",
       "         -7.6764e-02, -9.9706e-02, -2.2542e-01, -6.2899e-02,  2.5841e-02,\n",
       "          1.2201e-01, -7.4440e-02, -4.0869e-03, -1.5055e-01,  1.5514e-03,\n",
       "         -7.2199e-02, -6.6978e-02,  5.1169e-02,  3.2511e-02,  3.5741e-02,\n",
       "          1.3502e-01, -1.7663e-01,  1.8858e-01,  6.2952e-02,  4.4104e-02,\n",
       "         -3.3470e-02, -2.2379e-01, -1.2461e-01, -4.5936e-02,  1.9938e-01,\n",
       "          7.8751e-02,  9.1621e-02, -1.4924e-01,  8.2730e-02, -1.2267e-02,\n",
       "          3.9806e-02, -2.1395e-01, -1.0904e-01, -5.7976e-02, -9.6949e-02,\n",
       "         -8.0927e-03,  1.5231e-02,  9.1707e-02,  1.6528e-01, -2.3458e-03,\n",
       "          2.3411e-02,  9.9830e-02,  1.6885e-02,  7.3298e-02,  8.5890e-02,\n",
       "         -1.1331e-02,  5.3029e-02, -2.0385e-01,  4.4710e-02, -1.3403e-01,\n",
       "         -1.3749e-01,  1.6498e-01, -3.7632e-02,  1.4866e-01,  8.4602e-02,\n",
       "         -3.4403e-03, -2.0218e-01, -8.3446e-02, -5.3936e-02,  2.1343e-02,\n",
       "          1.9728e-01,  1.6815e-01, -1.3665e-01,  7.2037e-02,  2.2815e-01,\n",
       "         -1.7590e-01,  1.8568e-01, -5.3790e-02, -9.1042e-02,  1.2588e-02,\n",
       "         -1.7079e-01,  1.8049e-01, -1.9087e-01,  8.4461e-03, -1.9330e-01],\n",
       "        [ 1.4954e-02, -1.3372e-01,  2.0377e-01,  2.2938e-01, -1.1116e-01,\n",
       "          5.7733e-03,  1.9312e-01, -5.6188e-02,  1.2002e-02,  3.2597e-02,\n",
       "         -1.7729e-01,  1.9779e-01,  1.9300e-01,  1.2467e-01, -3.0352e-02,\n",
       "          8.2861e-02, -5.5838e-02,  1.5780e-02,  9.7686e-02, -4.5234e-02,\n",
       "         -1.1129e-02, -6.1812e-02,  1.5327e-01, -1.1349e-01, -2.2850e-01,\n",
       "         -2.0638e-01,  8.4418e-03, -2.2473e-01,  2.1970e-01, -4.5126e-02,\n",
       "         -8.5689e-02, -1.4598e-01, -1.9263e-02, -2.0067e-01,  2.3436e-02,\n",
       "         -3.0077e-02, -6.7117e-02,  3.6980e-02, -9.1049e-02, -4.4397e-02,\n",
       "         -6.2478e-02, -1.6602e-01,  1.9711e-01, -1.2819e-01, -2.4565e-02,\n",
       "          5.4689e-02,  3.9875e-02,  1.6734e-01, -4.5347e-02,  2.3221e-01,\n",
       "         -1.0586e-01, -1.1613e-01, -1.3483e-01,  2.0492e-01, -2.0776e-01,\n",
       "          2.1552e-01, -9.9722e-02,  8.9342e-03,  2.3024e-01,  1.6495e-01,\n",
       "          7.4190e-02, -5.4019e-02,  1.5603e-02, -1.7455e-01, -8.5629e-02,\n",
       "         -8.0312e-02,  2.5756e-02, -7.3600e-03, -1.0522e-01,  9.5228e-02,\n",
       "          1.2168e-01,  1.1862e-01,  5.5050e-02,  2.5221e-02, -1.4796e-01,\n",
       "         -2.3020e-01,  1.6304e-01,  5.3981e-02,  2.1812e-01,  1.0046e-01,\n",
       "          3.4860e-02,  1.8135e-01, -7.9023e-02,  6.8824e-03, -5.3962e-02,\n",
       "          2.2475e-01,  1.9476e-01, -1.1944e-01,  1.5941e-01,  2.2224e-01,\n",
       "         -1.2631e-01, -2.2943e-01,  9.2923e-02, -1.6053e-02,  8.6093e-02,\n",
       "         -9.0743e-02, -2.2324e-03,  2.1101e-01,  1.3074e-01, -1.7960e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1,bn1, relu, dropout,\n",
    "                            linear2,bn2, relu, dropout,\n",
    "                            linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.505852759\n",
      "Epoch: 0002 cost = 0.355073422\n",
      "Epoch: 0003 cost = 0.321320951\n",
      "Epoch: 0004 cost = 0.303041995\n",
      "Epoch: 0005 cost = 0.302864492\n",
      "Epoch: 0006 cost = 0.282366365\n",
      "Epoch: 0007 cost = 0.265034020\n",
      "Epoch: 0008 cost = 0.269699484\n",
      "Epoch: 0009 cost = 0.260018706\n",
      "Epoch: 0010 cost = 0.261773169\n",
      "Epoch: 0011 cost = 0.257436723\n",
      "Epoch: 0012 cost = 0.252168328\n",
      "Epoch: 0013 cost = 0.229561925\n",
      "Epoch: 0014 cost = 0.242550507\n",
      "Epoch: 0015 cost = 0.250869453\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "model.train()    # set the model to train mode (dropout=True)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 784).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9157999753952026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seungjun\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\seungjun\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()    # set the model to evaluation mode (dropout=False)\n",
    "\n",
    "    # Test the model using test sets\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = 0\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  6\n",
      "Prediction:  6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-1 Hidden node 수를 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 200, bias=True)\n",
    "linear2 = torch.nn.Linear(200, 150, bias=True)\n",
    "linear3 = torch.nn.Linear(150, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "bn1 = torch.nn.BatchNorm1d(200)\n",
    "bn2 = torch.nn.BatchNorm1d(150)\n",
    "\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = len(train_loader)\n",
    "model.train()    # set the model to train mode (dropout=True)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 784).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seungjun\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\seungjun\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9484500288963318\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for train sets\n",
    "X_test = mnist_train.train_data.view(-1, 28*28).float().to(device)\n",
    "Y_test = mnist_train.train_labels.to(device)\n",
    "\n",
    "prediction = model(X_test)\n",
    "correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "accuracy = 0\n",
    "accuracy = correct_prediction.float().mean()\n",
    "print('Accuracy:', accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9688000082969666\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for test sets\n",
    "with torch.no_grad():\n",
    "    model.eval()    # set the model to evaluation mode (dropout=False)\n",
    "\n",
    "    # Test the model using test sets\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = 0\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-2 Hidden node 수를 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 50, bias=True)\n",
    "linear2 = torch.nn.Linear(50, 50, bias=True)\n",
    "linear3 = torch.nn.Linear(50, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "bn1 = torch.nn.BatchNorm1d(50)\n",
    "bn2 = torch.nn.BatchNorm1d(50)\n",
    "\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.213821724\n",
      "Epoch: 0002 cost = 0.203128070\n",
      "Epoch: 0003 cost = 0.201647580\n",
      "Epoch: 0004 cost = 0.201174617\n",
      "Epoch: 0005 cost = 0.193975255\n",
      "Epoch: 0006 cost = 0.202385426\n",
      "Epoch: 0007 cost = 0.193503931\n",
      "Epoch: 0008 cost = 0.188855439\n",
      "Epoch: 0009 cost = 0.196626797\n",
      "Epoch: 0010 cost = 0.196404412\n",
      "Epoch: 0011 cost = 0.188807771\n",
      "Epoch: 0012 cost = 0.193488047\n",
      "Epoch: 0013 cost = 0.183583781\n",
      "Epoch: 0014 cost = 0.185089126\n",
      "Epoch: 0015 cost = 0.188467070\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "model.train()    # set the model to train mode (dropout=True)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 784).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.958899974822998\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for train sets\n",
    "X_test = mnist_train.train_data.view(-1, 28*28).float().to(device)\n",
    "Y_test = mnist_train.train_labels.to(device)\n",
    "\n",
    "prediction = model(X_test)\n",
    "correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "accuracy = 0\n",
    "accuracy = correct_prediction.float().mean()\n",
    "print('Accuracy:', accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9650999903678894\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for test sets\n",
    "with torch.no_grad():\n",
    "    model.eval()    # set the model to evaluation mode (dropout=False)\n",
    "\n",
    "    # Test the model using test sets\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = 0\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
